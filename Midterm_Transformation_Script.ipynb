{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8cbd324-b729-4087-8242-faba532429ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84e83dc-f266-45a6-b35b-6fb421da00d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------+----------+---------+-----------+---------+--------+----------+----------+---------+\n|TRANS_ID|PROD_KEY|STORE_KEY|  TRANS_DT|TRANS_TIME|SALES_QTY|SALES_PRICE|SALES_AMT|DISCOUNT|SALES_COST|SALES_MGRN|SHIP_COST|\n+--------+--------+---------+----------+----------+---------+-----------+---------+--------+----------+----------+---------+\n|  244054|  455222|     8103|2020-10-09|        12|     25.0|      37.94|   721.06|     0.1|    610.39|    338.01|     5.08|\n|  244056|  637817|     8103|2020-06-04|        16|      2.4|     999.99|  2423.98|     0.0|   4819.97|   -1820.0|    13.99|\n|  244058|  492902|     8103|2022-10-25|        17|     30.0|      14.03|   356.94|    0.08|    569.08|   -148.26|     9.37|\n|  244060|  612619|     8103|2022-01-10|        18|     13.6|     107.53|  1782.68|    0.08|   1547.29|    280.64|     5.81|\n|  244062| 1039077|     8103|2020-05-25|        18|     34.0|      27.18|   622.89|     0.1|    719.53|    204.49|     8.23|\n+--------+--------+---------+----------+----------+---------+-----------+---------+--------+----------+----------+---------+\n\nroot\n |-- TRANS_ID: integer (nullable = true)\n |-- PROD_KEY: integer (nullable = true)\n |-- STORE_KEY: integer (nullable = true)\n |-- TRANS_DT: date (nullable = true)\n |-- TRANS_TIME: integer (nullable = true)\n |-- SALES_QTY: float (nullable = true)\n |-- SALES_PRICE: float (nullable = true)\n |-- SALES_AMT: float (nullable = true)\n |-- DISCOUNT: float (nullable = true)\n |-- SALES_COST: float (nullable = true)\n |-- SALES_MGRN: float (nullable = true)\n |-- SHIP_COST: float (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, FloatType\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "date_str = sys.argv[1]\n",
    "\n",
    "#creating Spark Session\n",
    "#change to yarn for EMR Cluster\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"demo\").getOrCreate()\n",
    "\n",
    "salesSchema = StructType([\n",
    "    StructField(\"TRANS_ID\", IntegerType(), True),\n",
    "    StructField(\"PROD_KEY\", IntegerType(), True),\n",
    "    StructField(\"STORE_KEY\", IntegerType(), True),\n",
    "    StructField(\"TRANS_DT\", DateType(), True),\n",
    "    StructField(\"TRANS_TIME\", IntegerType(), True),\n",
    "    StructField(\"SALES_QTY\", FloatType(), True),\n",
    "    StructField(\"SALES_PRICE\", FloatType(), True),\n",
    "    StructField(\"SALES_AMT\", FloatType(), True),\n",
    "    StructField(\"DISCOUNT\", FloatType(), True),\n",
    "    StructField(\"SALES_COST\", FloatType(), True),\n",
    "    StructField(\"SALES_MGRN\", FloatType(), True),\n",
    "    StructField(\"SHIP_COST\", FloatType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#read a file from S3\n",
    "#change to s3 bucket when running in EMR\n",
    "sales_df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(salesSchema).csv(\"/FileStore/tables/sales_20230723.csv\")#\"file:////home/ec2-user/midterm/data/sales_20230722.csv\")\n",
    "\n",
    "#total sales quantity by week, store, and product\n",
    "sales_df.createOrReplaceTempView(\"sales\")\n",
    "\n",
    "df_sum_sales_quantity = spark.sql(\"select * from sales limit 5;\")\n",
    "df_sum_sales_quantity.show() \n",
    "\n",
    "df_sum_sales_quantity.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5b91398-8276-491e-987c-b1547e83ffc7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b75218-23a2-48b5-8a89-d3e2b88e48d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----+-----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n|PROD_KEY|     PROD_NAME|  VOL|  WGT|BRAND_NAME|STATUS_CODE|STATUS_CODE_NAME|CATEGORY_KEY|CATEGORY_NAME|SUBCATEGORY_KEY|SUBCATEGORY_NAME|\n+--------+--------------+-----+-----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n|  657768|Product-657768| 1.22| 28.6|  brand-14|          1|          active|           4|   category-4|              1|   subcategory-1|\n|  293693|Product-293693|10.54| 6.29|  brand-13|          1|          active|           1|   category-1|              4|   subcategory-4|\n|  484597|Product-484597| 3.11|14.88|   brand-7|          1|          active|           1|   category-1|              4|   subcategory-4|\n|  939925|Product-939925|16.12| 0.93|  brand-18|          1|          active|           5|   category-5|              3|   subcategory-3|\n|  234470|Product-234470|12.04|70.27|   brand-7|          1|          active|           5|   category-5|              1|   subcategory-1|\n+--------+--------------+-----+-----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n\nroot\n |-- PROD_KEY: integer (nullable = true)\n |-- PROD_NAME: string (nullable = true)\n |-- VOL: float (nullable = true)\n |-- WGT: float (nullable = true)\n |-- BRAND_NAME: string (nullable = true)\n |-- STATUS_CODE: integer (nullable = true)\n |-- STATUS_CODE_NAME: string (nullable = true)\n |-- CATEGORY_KEY: integer (nullable = true)\n |-- CATEGORY_NAME: string (nullable = true)\n |-- SUBCATEGORY_KEY: integer (nullable = true)\n |-- SUBCATEGORY_NAME: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "productSchema = StructType([\n",
    "    StructField(\"PROD_KEY\", IntegerType(), True),\n",
    "    StructField(\"PROD_NAME\", StringType(), True),\n",
    "    StructField(\"VOL\", FloatType(), True),\n",
    "    StructField(\"WGT\", FloatType(), True),\n",
    "    StructField(\"BRAND_NAME\", StringType(), True),\n",
    "    StructField(\"STATUS_CODE\", IntegerType(), True),\n",
    "    StructField(\"STATUS_CODE_NAME\", StringType(), True),\n",
    "    StructField(\"CATEGORY_KEY\", IntegerType(), True),\n",
    "    StructField(\"CATEGORY_NAME\", StringType(), True),\n",
    "    StructField(\"SUBCATEGORY_KEY\", IntegerType(), True),\n",
    "    StructField(\"SUBCATEGORY_NAME\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#read a file from S3\n",
    "#change to s3 bucket when running in EMR\n",
    "product_df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(productSchema).csv(\"/FileStore/tables/product_20230723.csv\")#\"file:////home/ec2-user/midterm/data/sales_20230722.csv\")\n",
    "\n",
    "#total sales quantity by week, store, and product\n",
    "product_df.createOrReplaceTempView(\"product\")\n",
    "\n",
    "product_df = spark.sql(\"select * from product limit 5;\")\n",
    "product_df.show() \n",
    "\n",
    "product_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ebf5e12-4680-4cc8-aa3d-9c4007b609fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Inventory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eccb25e-40c7-4174-ac70-ca317156e80a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|    CAL_DT|STORE_KEY|PROD_KEY|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|PROMOTION_FLG|NEXT_DELIVERY_DT|\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|2020-01-01|      248|  539839|                33.28|                 28.16|               1|      0.0|         true|      2009-01-14|\n|2020-01-01|      248| 1064589|                 7.56|                  8.19|               0|      1.0|        false|      2009-01-06|\n|2020-01-01|     1054|  539839|                 38.4|                  57.6|               0|      1.0|         true|      2009-01-10|\n|2020-01-01|     1054| 1064589|                13.68|                  7.92|               1|      1.0|         true|      2009-01-16|\n|2020-01-01|     1103|  539839|                 8.64|                 48.96|               1|      1.0|        false|      2009-01-15|\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n\nroot\n |-- CAL_DT: date (nullable = true)\n |-- STORE_KEY: integer (nullable = true)\n |-- PROD_KEY: integer (nullable = true)\n |-- INVENTORY_ON_HAND_QTY: float (nullable = true)\n |-- INVENTORY_ON_ORDER_QTY: float (nullable = true)\n |-- OUT_OF_STOCK_FLG: integer (nullable = true)\n |-- WASTE_QTY: float (nullable = true)\n |-- PROMOTION_FLG: boolean (nullable = true)\n |-- NEXT_DELIVERY_DT: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "inventorySchema = StructType([\n",
    "    StructField(\"CAL_DT\", DateType(), True),\n",
    "    StructField(\"STORE_KEY\", IntegerType(), True),\n",
    "    StructField(\"PROD_KEY\", IntegerType(), True),\n",
    "    StructField(\"INVENTORY_ON_HAND_QTY\", FloatType(), True),\n",
    "    StructField(\"INVENTORY_ON_ORDER_QTY\", FloatType(), True),\n",
    "    StructField(\"OUT_OF_STOCK_FLG\", IntegerType(), True),\n",
    "    StructField(\"WASTE_QTY\", FloatType(), True),\n",
    "    StructField(\"PROMOTION_FLG\", BooleanType(), True),\n",
    "    StructField(\"NEXT_DELIVERY_DT\", DateType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#read a file from S3\n",
    "#change to s3 bucket when running in EMR\n",
    "inventory_df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(inventorySchema).csv(\"/FileStore/tables/inventory_20230723.csv\")#\"file:////home/ec2-user/midterm/data/sales_20230722.csv\")\n",
    "\n",
    "#total sales quantity by week, store, and product\n",
    "inventory_df.createOrReplaceTempView(\"inventory\")\n",
    "\n",
    "inventory_df = spark.sql(\"select * from inventory limit 5;\")\n",
    "inventory_df.show() \n",
    "\n",
    "inventory_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a691061-39be-48e3-86ba-c32763454fc7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "911e2ba5-9877-4f45-8291-65c7b8b49fc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+-------+-------+------+--------+--------+-------------+-------------+-------------+----------+----------+-----------+-------------+--------------+--------+---------+\n|STORE_KEY|STORE_NUM|  STORE_DESC|   ADDR|   CITY|REGION|CNTRY_CD|CNTRY_NM|POSTAL_ZIP_CD|PROV_STATE_CD|STORE_TYPE_CD|FRNCHS_FLG|STORE_SIZE|MARKET_NAME|SUBMARKET_KEY|SUBMARKET_NAME|LATITUDE|LONGITUDE|\n+---------+---------+------------+-------+-------+------+--------+--------+-------------+-------------+-------------+----------+----------+-----------+-------------+--------------+--------+---------+\n|      248|      248|store_desc42|addr_42|city_42|   \\\\N|      US|      US|          \\\\N|           WI|           WI|      null|      null|        \\\\N|         null|            22|    null|      3.0|\n|     1054|     1054| store_desc1| addr_1| city_1|   \\\\N|      US|      US|          \\\\N|           IN|           IN|      null|      null|        \\\\N|         null|            24|    null|      1.0|\n|     1103|     1103| store_desc2| addr_2| city_2|   \\\\N|      US|      US|          \\\\N|           OH|           OH|      null|      null|        \\\\N|         null|            24|    null|      1.0|\n|     1104|     1104| store_desc3| addr_3| city_3|   \\\\N|      US|      US|          \\\\N|           OH|           OH|      null|      null|        \\\\N|         null|            21|    null|      1.0|\n|     1106|     1106| store_desc4| addr_4| city_4|   \\\\N|      US|      US|          \\\\N|           MI|           MI|      null|      null|        \\\\N|         null|            21|    null|      1.0|\n+---------+---------+------------+-------+-------+------+--------+--------+-------------+-------------+-------------+----------+----------+-----------+-------------+--------------+--------+---------+\n\nroot\n |-- STORE_KEY: integer (nullable = true)\n |-- STORE_NUM: integer (nullable = true)\n |-- STORE_DESC: string (nullable = true)\n |-- ADDR: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- REGION: string (nullable = true)\n |-- CNTRY_CD: string (nullable = true)\n |-- CNTRY_NM: string (nullable = true)\n |-- POSTAL_ZIP_CD: string (nullable = true)\n |-- PROV_STATE_CD: string (nullable = true)\n |-- STORE_TYPE_CD: string (nullable = true)\n |-- FRNCHS_FLG: boolean (nullable = true)\n |-- STORE_SIZE: float (nullable = true)\n |-- MARKET_NAME: string (nullable = true)\n |-- SUBMARKET_KEY: integer (nullable = true)\n |-- SUBMARKET_NAME: string (nullable = true)\n |-- LATITUDE: float (nullable = true)\n |-- LONGITUDE: float (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "storeSchema = StructType([\n",
    "    StructField(\"STORE_KEY\", IntegerType(), True),\n",
    "    StructField(\"STORE_NUM\", IntegerType(), True),\n",
    "    StructField(\"STORE_DESC\", StringType(), True),\n",
    "    StructField(\"ADDR\", StringType(), True),\n",
    "    StructField(\"CITY\", StringType(), True),\n",
    "    StructField(\"REGION\", StringType(), True),\n",
    "    StructField(\"CNTRY_CD\", StringType(), True),\n",
    "    StructField(\"CNTRY_NM\", StringType(), True),\n",
    "    StructField(\"POSTAL_ZIP_CD\", StringType(), True),\n",
    "    StructField(\"PROV_STATE_CD\", StringType(), True),\n",
    "    StructField(\"STORE_TYPE_CD\", StringType(), True),\n",
    "    StructField(\"FRNCHS_FLG\", BooleanType(), True),\n",
    "    StructField(\"STORE_SIZE\", FloatType(), True),\n",
    "    StructField(\"MARKET_NAME\", StringType(), True),\n",
    "    StructField(\"SUBMARKET_KEY\", IntegerType(), True),\n",
    "    StructField(\"SUBMARKET_NAME\", StringType(), True),\n",
    "    StructField(\"LATITUDE\", FloatType(), True),\n",
    "    StructField(\"LONGITUDE\", FloatType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#schema(storeSchema).\n",
    "\n",
    "#read a file from S3\n",
    "#change to s3 bucket when running in EMR\n",
    "store_df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(storeSchema).csv(\"/FileStore/tables/store_20230723.csv\")#\"file:////home/ec2-user/midterm/data/sales_20230722.csv\")\n",
    "\n",
    "#total sales quantity by week, store, and product\n",
    "store_df.createOrReplaceTempView(\"store\")\n",
    "\n",
    "store_df = spark.sql(\"select * from store limit 5;\")\n",
    "#spark.sql(\"select distinct STORE_SIZE from store order by STORE_SIZE DESC limit 5;\")\n",
    "store_df.show() \n",
    "\n",
    "store_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1971b20f-c4b3-4d2c-a070-5e90144a5e81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[34]: ['STORE_KEY',\n 'STORE_NUM',\n 'STORE_DESC',\n 'ADDR',\n 'CITY',\n 'REGION',\n 'CNTRY_CD',\n 'CNTRY_NM',\n 'POSTAL_ZIP_CD',\n 'PROV_STATE_CD',\n 'STORE_TYPE_CD',\n 'FRNCHS_FLG',\n 'STORE_SIZE',\n 'MARKET_NAME',\n 'SUBMARKET_KEY',\n 'SUBMARKET_NAME',\n 'LATITUDE',\n 'LONGITUDE']"
     ]
    }
   ],
   "source": [
    "store_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dda5384-a0ae-4f1f-9b76-267a4ebb5deb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Calendar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57d11ac0-eb76-45e9-a435-081e0a7b48a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|    CAL_DT|CAL_TYPE_DESC|DAY_OF_WK_NUM|DAY_OF_WK_DESC|YR_NUM|WK_NUM|YR_WK_NUM|MNTH_NUM|YR_MNTH_NUM|QTR_NUM|YR_QTR_NUM|\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|1998-06-04|       Fiscal|            4|      Thursday|  1998|    23|   199823|       6|      19986|      2|     19982|\n|1998-04-27|       Fiscal|            1|        Monday|  1998|    18|   199818|       5|      19985|      2|     19982|\n|1998-05-13|       Fiscal|            3|     Wednesday|  1998|    20|   199820|       5|      19985|      2|     19982|\n|1998-02-08|       Fiscal|            0|        Sunday|  1998|     7|   199807|       2|      19982|      1|     19981|\n|1998-04-08|       Fiscal|            3|     Wednesday|  1998|    15|   199815|       4|      19984|      2|     19982|\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n\nroot\n |-- CAL_DT: date (nullable = true)\n |-- CAL_TYPE_DESC: string (nullable = true)\n |-- DAY_OF_WK_NUM: integer (nullable = true)\n |-- DAY_OF_WK_DESC: string (nullable = true)\n |-- YR_NUM: integer (nullable = true)\n |-- WK_NUM: integer (nullable = true)\n |-- YR_WK_NUM: integer (nullable = true)\n |-- MNTH_NUM: integer (nullable = true)\n |-- YR_MNTH_NUM: integer (nullable = true)\n |-- QTR_NUM: integer (nullable = true)\n |-- YR_QTR_NUM: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "calendarSchema = StructType([\n",
    "    StructField(\"CAL_DT\", DateType(), True),\n",
    "    StructField(\"CAL_TYPE_DESC\", StringType(), True),\n",
    "    StructField(\"DAY_OF_WK_NUM\", IntegerType(), True),\n",
    "    StructField(\"DAY_OF_WK_DESC\", StringType(), True),\n",
    "    StructField(\"YR_NUM\", IntegerType(), True),\n",
    "    StructField(\"WK_NUM\", IntegerType(), True),\n",
    "    StructField(\"YR_WK_NUM\", IntegerType(), True),\n",
    "    StructField(\"MNTH_NUM\", IntegerType(), True),\n",
    "    StructField(\"YR_MNTH_NUM\", IntegerType(), True),\n",
    "    StructField(\"QTR_NUM\", IntegerType(), True),\n",
    "    StructField(\"YR_QTR_NUM\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "# .schema(storeSchema)\n",
    "#read a file from S3\n",
    "#change to s3 bucket when running in EMR\n",
    "calendar_df = spark.read.option(\"header\", \"true\").option(\"delimiter\", \",\").schema(calendarSchema).csv(\"/FileStore/tables/calendar_20230723.csv\")#\"file:////home/ec2-user/midterm/data/sales_20230722.csv\")\n",
    "\n",
    "#total sales quantity by week, store, and product\n",
    "calendar_df.createOrReplaceTempView(\"calendar\")\n",
    "\n",
    "calendar_df = spark.sql(\"select * from calendar limit 5;\")\n",
    "calendar_df.show() \n",
    "\n",
    "calendar_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38b7b1ee-11b7-4a52-ac66-42c4fd22dc00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Q1 : stock level by then end of the week : stock_on_hand_qty by the end of the week (only the stock level at the end day of the week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d17c2694-df0c-4f1f-9b25-fff1eb43fcdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-------------+\n|    CAL_DT|INVENTORY_ON_HAND_QTY|DAY_OF_WK_NUM|\n+----------+---------------------+-------------+\n|2023-07-21|                  5.6|            5|\n|2023-07-21|                54.18|            5|\n|2023-07-21|                31.68|            5|\n|2023-07-21|                 5.76|            5|\n|2023-07-21|                13.44|            5|\n|2023-07-21|                 24.8|            5|\n|2023-07-21|                 19.8|            5|\n|2023-07-21|                  4.0|            5|\n|2023-07-21|                 9.45|            5|\n|2023-07-21|                 5.12|            5|\n+----------+---------------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select i.CAL_DT, i.INVENTORY_ON_HAND_QTY, c.DAY_OF_WK_NUM\n",
    "          from inventory i\n",
    "          join calendar c\n",
    "          on i.CAL_DT = c.CAL_DT\n",
    "          where c.DAY_OF_WK_NUM =5\n",
    "          order by i.cal_dt desc\n",
    "          limit 10;\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8acc8d2-df8c-4280-9dad-ad610a7a43bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|    CAL_DT|STORE_KEY|PROD_KEY|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|PROMOTION_FLG|NEXT_DELIVERY_DT|\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|2023-07-23|      248|  752280|                 12.0|                  18.0|               0|      1.0|         true|      2012-08-12|\n|2023-07-23|     1103|  752280|                 38.0|                  10.0|               1|      1.0|         true|      2012-08-10|\n|2023-07-23|      248|  954944|                 44.8|                 42.56|               0|      1.0|        false|      2012-08-01|\n|2023-07-23|     1054|  752280|                  9.8|                  25.2|               0|      1.0|        false|      2012-08-04|\n|2023-07-23|     1054|  954944|                 22.4|                  57.6|               0|      1.0|         true|      2012-08-04|\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|    CAL_DT|CAL_TYPE_DESC|DAY_OF_WK_NUM|DAY_OF_WK_DESC|YR_NUM|WK_NUM|YR_WK_NUM|MNTH_NUM|YR_MNTH_NUM|QTR_NUM|YR_QTR_NUM|\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|2027-01-02|       Fiscal|            6|      Saturday|  2026|    53|   202653|      12|     202612|      4|     20264|\n|2027-01-01|       Fiscal|            5|        Friday|  2026|    53|   202653|      12|     202612|      4|     20264|\n|2026-12-31|       Fiscal|            4|      Thursday|  2026|    53|   202653|      12|     202612|      4|     20264|\n|2026-12-30|       Fiscal|            3|     Wednesday|  2026|    53|   202653|      12|     202612|      4|     20264|\n|2026-12-29|       Fiscal|            2|       Tuesday|  2026|    53|   202653|      12|     202612|      4|     20264|\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n\n+-------------+\n|DAY_OF_WK_NUM|\n+-------------+\n|            1|\n|            3|\n|            5|\n|            4|\n|            0|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * \n",
    "          from inventory  \n",
    "          order by cal_dt desc\n",
    "          limit 5;\n",
    "          \"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"select * \n",
    "          from calendar  \n",
    "          order by cal_dt desc\n",
    "          limit 5;\n",
    "          \"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"select distinct DAY_OF_WK_NUM\n",
    "          from calendar  \n",
    "          limit 5;\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82a77787-b9d2-4d05-9706-9ccbe877fa0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b8c894b-a39a-499f-8a3c-741ef0f27a67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT MAX(stock_on_hand_qty) AS stock_level_by_end_of_week\n",
    "FROM stock_table\n",
    "JOIN calendar_table ON stock_table.date = calendar_table.date\n",
    "WHERE calendar_table.week_end_date = (SELECT MAX(week_end_date) FROM calendar_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "452903b2-7452-44ad-8bb8-b1e4b503c850",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f82e7eb3-0552-4841-89fa-6c6772ff2c8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/sales_20230723.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_sales = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "display(df_sales)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Midterm Transformation Script",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
